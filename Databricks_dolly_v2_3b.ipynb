{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "https://colab.research.google.com/drive/18tLZqid9EfG04XoH9cJnLT3YPROYUktD?usp=sharing"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Model card: https://huggingface.co/databricks/dolly-v2-3b\n",
                "\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install \"accelerate>=0.16.0,<1\" \"transformers[torch]>=4.28.1,<5\" \"torch>=1.13.1,<2\"\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "import torch\n",
                "import transformers\n",
                "\n"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Following cell downloads about 6GB from internet. May take some time\n",
                "\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "generate_text = transformers.pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n",
                "\n"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "res = generate_text(\"Explain to me the difference between nuclear fission and fusion.\")\n",
                "print(res[0][\"generated_text\"])"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "res = generate_text(\"Who first made programming language python?\")\n",
                "print(res[0][\"generated_text\"])"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "res = generate_text(\"Can you tell me about databricks/dolly-v2-3b?\")\n",
                "print(res[0][\"generated_text\"])"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "res = generate_text(\"Can you tell me how to finetune a large language model like yourself?\")\n",
                "print(res[0][\"generated_text\"])"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}